{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and dependencies\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oversampling using SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and dependencies\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno \n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,roc_curve,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the data into a Pandas DataFrame\n",
    "df5 = pd.read_csv(\"heart_2022_cleaned.csv\")\n",
    "\n",
    "# Define features set X\n",
    "X = df5.drop(\"HeartAttack\", axis=1)\n",
    "# Define target vector y\n",
    "y = df5[\"HeartAttack\"].values\n",
    "\n",
    "# Dealing with Imbalanced Data. Scale features to [0, 1] range\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# SMOTE for Resampling to balance the dataset\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
    "\n",
    "# Split the data into training, validation, and test using train_test_split with stratification\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled, \n",
    "    stratify=y_resampled,  # to maintain the same proportion of classes in both train and test sets\n",
    "    test_size=0.3,\n",
    "    random_state=78\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=78\n",
    ")\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler and Scale the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "\n",
    "# Define a grid of hyperparameters for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Implement GridSearchCV with cross-validation and early stopping\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and best cross-validation score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "val_predictions = best_rf_model.predict(X_val_scaled)\n",
    "val_acc_score = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation Accuracy Score: {val_acc_score}\")\n",
    "\n",
    "# Making predictions using the testing data\n",
    "test_predictions = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_rf_model.predict(X_train_scaled)\n",
    "y_val_pred = best_rf_model.predict(X_val_scaled)\n",
    "y_test_pred = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# and Predict Probabilities\n",
    "y_train_prob = best_rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_val_prob = best_rf_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_prob = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate losses\n",
    "train_loss = log_loss(y_train, y_train_prob)\n",
    "val_loss = log_loss(y_val, y_val_prob)\n",
    "test_loss = log_loss(y_test, y_test_prob)\n",
    "\n",
    "# Calculate errors\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "val_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print losses and errors\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Training Error: {train_error:.4f}\")\n",
    "print(f\"Validation Error: {val_error:.4f}\")\n",
    "print(f\"Test Error : {test_error:.4f}\")\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm_df)\n",
    "print(f\"Accuracy Score: {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, test_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling using RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "df5 = pd.read_csv(\"heart_2022_cleaned.csv\")\n",
    "\n",
    "# Define features set X\n",
    "X = df5.drop(\"HeartAttack\", axis=1)\n",
    "# Define target vector y\n",
    "y = df5[\"HeartAttack\"].values\n",
    "\n",
    "# Dealing with Imbalanced Data. Scale features to [0, 1] range\n",
    "X_scaled = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "# Random UnderSampler for balancing the dataset\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = rus.fit_resample(X_smote, y_smote)\n",
    "\n",
    "# Split the data into training, validation, and test using train_test_split with stratification\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X_resampled, \n",
    "    y_resampled, \n",
    "    stratify=y_resampled,  # to maintain the same proportion of classes in both train and test sets\n",
    "    test_size=0.3,\n",
    "    random_state=78\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp,\n",
    "    y_temp,\n",
    "    stratify=y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=78\n",
    ")\n",
    "\n",
    "# Create a StandardScaler instance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler and Scale the data\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=500, random_state=78)\n",
    "\n",
    "# Define a grid of hyperparameters for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Implement GridSearchCV with cross-validation and early stopping\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,  # 3-fold cross-validation\n",
    "    n_jobs=-1,\n",
    "    scoring='accuracy',\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Print the best parameters and best cross-validation score\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Best cross-validation accuracy: {grid_search.best_score_}\")\n",
    "\n",
    "# Evaluate the best model on the validation set\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "val_predictions = best_rf_model.predict(X_val_scaled)\n",
    "val_acc_score = accuracy_score(y_val, val_predictions)\n",
    "print(f\"Validation Accuracy Score: {val_acc_score}\")\n",
    "\n",
    "# Making predictions using the testing data\n",
    "test_predictions = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Predictions\n",
    "y_train_pred = best_rf_model.predict(X_train_scaled)\n",
    "y_val_pred = best_rf_model.predict(X_val_scaled)\n",
    "y_test_pred = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# and Predict Probabilities\n",
    "y_train_prob = best_rf_model.predict_proba(X_train_scaled)[:, 1]\n",
    "y_val_prob = best_rf_model.predict_proba(X_val_scaled)[:, 1]\n",
    "y_test_prob = best_rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculate losses\n",
    "train_loss = log_loss(y_train, y_train_prob)\n",
    "val_loss = log_loss(y_val, y_val_prob)\n",
    "test_loss = log_loss(y_test, y_test_prob)\n",
    "\n",
    "# Calculate errors\n",
    "train_error = 1 - accuracy_score(y_train, y_train_pred)\n",
    "val_error = 1 - accuracy_score(y_val, y_val_pred)\n",
    "test_error = 1 - accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print losses and errors\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Training Error: {train_error:.4f}\")\n",
    "print(f\"Validation Error: {val_error:.4f}\")\n",
    "print(f\"Test Error : {test_error:.4f}\")\n",
    "\n",
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, test_predictions)\n",
    "cm_df = pd.DataFrame(cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"])\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, test_predictions)\n",
    "\n",
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm_df)\n",
    "print(f\"Accuracy Score: {acc_score}\")\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, test_predictions))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
