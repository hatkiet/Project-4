{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170dbe29-80e3-464a-b003-6b54f6ceeef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 324 candidates, totalling 972 fits\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load data set into pandas\n",
    "df = pd.read_csv(\"Cleaned_dataset.csv\")\n",
    "\n",
    "# Identify binary columns\n",
    "binary_columns = [column for column in df.columns if df[column].nunique() == 2]\n",
    "# Convert binary columns to 0 and 1\n",
    "for col in binary_columns:\n",
    "    unique_values = df[col].unique()\n",
    "    if set(unique_values) == {\"Yes\", \"No\"}:\n",
    "        df[col] = df[col].map({\"Yes\": 1, \"No\": 0})\n",
    "\n",
    "categorical_columns = ['Sex', 'GeneralHealth', 'LastCheckupTime', 'RemovedTeeth', 'HadDiabetes',\n",
    "                       'SmokerStatus', 'ECigaretteUsage', 'RaceEthnicityCategory', 'AgeCategory',\n",
    "                       'HighRiskLastYear', 'CovidPos']\n",
    "\n",
    "# Extract the categorical columns into a new DataFrame\n",
    "Categorical_col = df[categorical_columns]\n",
    "\n",
    "# Use pd.get_dummies to transform the categorical columns\n",
    "Transform_df = pd.get_dummies(Categorical_col, dtype=int)\n",
    "\n",
    "# Select numeric columns\n",
    "numeric_columns = df.select_dtypes(include=[\"float64\"]).columns\n",
    "df_numeric = df[numeric_columns]\n",
    "\n",
    "# Create standard scaler instance, fitting it, and scaling it\n",
    "scaler = StandardScaler()\n",
    "scaled_numeric_df = pd.DataFrame(scaler.fit_transform(df_numeric), columns=numeric_columns)\n",
    "\n",
    "# Drop the original columns\n",
    "df = df.drop(columns=categorical_columns + numeric_columns.tolist())\n",
    "\n",
    "# Combine the original DataFrame and the dummy variables DataFrame\n",
    "merged_df = pd.concat([df, Transform_df, scaled_numeric_df], axis=1)\n",
    "merged_df = merged_df.drop(columns='State')\n",
    "\n",
    "\n",
    "# Split the data into features and target variable\n",
    "X = merged_df.drop(columns=\"HadHeartAttack\")\n",
    "y = merged_df[\"HadHeartAttack\"]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42), \n",
    "                              param_grid=rf_param_grid, \n",
    "                              cv=3, \n",
    "                              n_jobs=-1, \n",
    "                              verbose=2)\n",
    "\n",
    "rf_grid_search.fit(X_train, y_train)\n",
    "best_rf = rf_grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned Random Forest model\n",
    "y_pred_test_rf = best_rf.predict(X_test)\n",
    "print(\"Tuned Random Forest Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0e6caa-9c06-482d-9160-00796b1c72f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning for Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "gb_grid_search = GridSearchCV(estimator=GradientBoostingClassifier(random_state=42), \n",
    "                              param_grid=gb_param_grid, \n",
    "                              cv=3, \n",
    "                              n_jobs=-1, \n",
    "                              verbose=2)\n",
    "gb_grid_search.fit(X_train, y_train)\n",
    "best_gb = gb_grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the tuned Gradient Boosting model\n",
    "y_pred_test_gb = best_gb.predict(X_test)\n",
    "print(\"Tuned Gradient Boosting Test Set Evaluation:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test_gb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_test_gb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_test_gb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674bc5d2-4251-414a-9a0e-432a106d2c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison of accuracy\n",
    "labels = ['Random Forest', 'Gradient Boosting']\n",
    "accuracies = [\n",
    "    accuracy_score(y_test, y_pred_test_rf),\n",
    "    accuracy_score(y_test, y_pred_test_gb)\n",
    "]\n",
    "\n",
    "plt.bar(labels, accuracies, color=['orange', 'green'])\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Comparison of Model Accuracy on Test Set')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98210459-2c03-4fbf-9d04-d599dd5a4b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the comparison of precision, recall, and f1-score\n",
    "labels = ['Precision', 'Recall', 'F1-score']\n",
    "class_0_scores_rf = [precision_score(y_test, y_pred_test_rf, pos_label=0), recall_score(y_test, y_pred_test_rf, pos_label=0), f1_score(y_test, y_pred_test_rf, pos_label=0)]\n",
    "class_1_scores_rf = [precision_score(y_test, y_pred_test_rf, pos_label=1), recall_score(y_test, y_pred_test_rf, pos_label=1), f1_score(y_test, y_pred_test_rf, pos_label=1)]\n",
    "class_0_scores_gb = [precision_score(y_test, y_pred_test_gb, pos_label=0), recall_score(y_test, y_pred_test_gb, pos_label=0), f1_score(y_test, y_pred_test_gb, pos_label=0)]\n",
    "class_1_scores_gb = [precision_score(y_test, y_pred_test_gb, pos_label=1), recall_score(y_test, y_pred_test_gb, pos_label=1), f1_score(y_test, y_pred_test_gb, pos_label=1)]\n",
    "\n",
    "x = list(range(len(labels)))\n",
    "width = 0.35\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "rects1 = ax.bar([i - width for i in x], class_0_scores_rf, width, label='Class 0 - RF')\n",
    "rects2 = ax.bar(x, class_1_scores_rf, width, label='Class 1 - RF')\n",
    "rects3 = ax.bar([i + width for i in x], class_0_scores_gb, width, label='Class 0 - GB')\n",
    "rects4 = ax.bar([i + 2*width for i in x], class_1_scores_gb, width, label='Class 1 - GB')\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Scores')\n",
    "ax.set_title('Comparison of Precision, Recall, and F1-score by Class and Model')\n",
    "ax.set_xticks([i + width/2 for i in x])\n",
    "ax.set_xticklabels(labels)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
