{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee91658-3746-4e21-80d2-e3b0e5c9bc94",
   "metadata": {},
   "source": [
    "### Without GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7b67819-c3ac-4831-afd4-16669b9cedec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': [RandomForestClassifier(), 0.7677120847563778],\n",
       " 'svm': [SVC(), 0.807542692935967],\n",
       " 'logistic_regression': [LogisticRegression(), 0.7810540716209525],\n",
       " 'Decision_tree': [DecisionTreeClassifier(), 0.5176839350841428],\n",
       " 'SGD': [SGDClassifier(), 0.8100487075677753]}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"ready_for_ML.csv\")\n",
    "df.head()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = df.drop(columns=\"HadHeartAttack\")\n",
    "y = df[\"HadHeartAttack\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Training our models on training dataset with default hyper-parameters:\n",
    "estimators_nogs = [\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('svm', SVC()),\n",
    "    ('logistic_regression', LogisticRegression()),\n",
    "    ('Decision_tree', DecisionTreeClassifier()),\n",
    "    ('SGD', SGDClassifier())\n",
    "]\n",
    "\n",
    "param_grids_nogs = {\n",
    "    'random_forest': {},\n",
    "    'svm': {},\n",
    "    'logistic_regression': {},\n",
    "    'Decision_tree': {},\n",
    "    'SGD': {}\n",
    "}\n",
    "\n",
    "best_models_nogs = {}\n",
    "\n",
    "for name, estimator in estimators_nogs:\n",
    "    grid_search = GridSearchCV(estimator, param_grids_nogs[name], scoring=['accuracy', 'precision', 'recall'], refit='precision', cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models_nogs[name] = [grid_search.best_estimator_, grid_search.best_score_]\n",
    "\n",
    "best_models_nogs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c53880f-0623-448e-ac30-5083909e1911",
   "metadata": {},
   "source": [
    "### With GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a17d7e8-dacd-49c0-9a94-984091a950d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "9 fits failed out of a total of 18.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1474, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1172, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.86478783        nan 0.86506687        nan 0.865027  ]\n",
      "  warnings.warn(\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.78077758        nan 0.78105407        nan 0.78084657]\n",
      "  warnings.warn(\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [       nan 0.52188081        nan 0.52335485        nan 0.52335485]\n",
      "  warnings.warn(\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:547: FitFailedWarning: \n",
      "9 fits failed out of a total of 27.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "4 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'epsilon_insensitive', 'huber', 'log_loss', 'squared_error', 'squared_epsilon_insensitive', 'perceptron', 'modified_huber', 'hinge', 'squared_hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "2 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'perceptron', 'epsilon_insensitive', 'log_loss', 'squared_epsilon_insensitive', 'squared_error', 'squared_hinge', 'huber', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 1467, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'modified_huber', 'log_loss', 'squared_epsilon_insensitive', 'perceptron', 'squared_error', 'epsilon_insensitive', 'huber', 'squared_hinge', 'hinge'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.86717957 0.86715964 0.86717957        nan        nan        nan\n",
      " 0.81326625 0.83241948 0.82087904]\n",
      "  warnings.warn(\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.81004871 0.80993214 0.81004871        nan        nan        nan\n",
      " 0.65690035 0.66896854 0.66550364]\n",
      "  warnings.warn(\n",
      "C:\\Users\\faran\\anaconda3\\envs\\dev\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [0.50446897 0.50446897 0.50446897        nan        nan        nan\n",
      " 0.41476383 0.45287458 0.56961142]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'random_forest': [RandomForestClassifier(max_depth=10, n_estimators=200),\n",
       "  0.8003369594908306],\n",
       " 'svm': [SVC(C=0.1, kernel='linear'), 0.8100487075677753],\n",
       " 'logistic_regression': [LogisticRegression(C=1), 0.7810540716209525],\n",
       " 'Decision_tree': [DecisionTreeClassifier(max_depth=10), 0.6889667737117656],\n",
       " 'SGD': [SGDClassifier(penalty='l1'), 0.8100487075677753]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Constructing a grid space of hyper-parameters for our models:\n",
    "estimators_gs = [\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('svm', SVC()),\n",
    "    ('logistic_regression', LogisticRegression()),\n",
    "    ('Decision_tree', DecisionTreeClassifier()),\n",
    "    ('SGD', SGDClassifier())\n",
    "]\n",
    "\n",
    "# Defining a parameter grid space for each estimator:\n",
    "param_grids_gs = {\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'Decision_tree': {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'SGD': {\n",
    "        'loss': ['hinge', 'log', 'perceptron'],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models_gs = {}\n",
    "\n",
    "for name, estimator in estimators_gs:\n",
    "    grid_search = GridSearchCV(estimator, param_grids_gs[name], scoring=['accuracy', 'precision', 'recall'], refit='precision', cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models_gs[name] = [grid_search.best_estimator_, grid_search.best_score_]\n",
    "\n",
    "best_models_gs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d9bbc9-4ac9-4a68-ad27-f5cd10494a47",
   "metadata": {},
   "source": [
    "### GridSearchCV on the models using only the selected columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6170aea-fbed-40ab-b103-0be70e0d7bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5ce07a6-148f-4423-b752-a2a9b51a967c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'random_forest': [RandomForestClassifier(max_depth=10), 0.8087948439500164],\n",
       " 'svm': [SVC(C=0.1, kernel='linear'), 0.8100487075677753],\n",
       " 'logistic_regression': [LogisticRegression(C=0.1), 0.8100487075677753],\n",
       " 'Decision_tree': [DecisionTreeClassifier(max_depth=10, min_samples_split=5),\n",
       "  0.7705721239702964],\n",
       " 'SGD': [SGDClassifier(penalty='l1'), 0.8100487075677753]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns to keep\n",
    "columns_to_keep = ['HadAngina', 'BMI', 'WeightInKilograms', 'HeightInMeters', 'SleepHours', 'PhysicalHealthDays', 'MentalHealthDays']\n",
    "\n",
    "# Filter the dataset to include only the selected columns plus the target column\n",
    "filtered_df = df[columns_to_keep + ['HadHeartAttack']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X = filtered_df.drop(columns=\"HadHeartAttack\")\n",
    "y = filtered_df[\"HadHeartAttack\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# Constructing a grid space of hyper-parameters for our models\n",
    "estimators_fs = [\n",
    "    ('random_forest', RandomForestClassifier()),\n",
    "    ('svm', SVC()),\n",
    "    ('logistic_regression', LogisticRegression()),\n",
    "    ('Decision_tree', DecisionTreeClassifier()),\n",
    "    ('SGD', SGDClassifier())\n",
    "]\n",
    "\n",
    "# Defining a parameter grid space for each estimator\n",
    "param_grids_fs = {\n",
    "    'random_forest': {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [None, 10, 20]\n",
    "    },\n",
    "    'svm': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['linear', 'rbf']\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'penalty': ['l1', 'l2']\n",
    "    },\n",
    "    'Decision_tree': {\n",
    "        'max_depth': [None, 10, 20],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    'SGD': {\n",
    "        'loss': ['hinge', 'log', 'perceptron'],\n",
    "        'penalty': ['l1', 'l2', 'elasticnet']\n",
    "    }\n",
    "}\n",
    "\n",
    "best_models_fs = {}\n",
    "\n",
    "for name, estimator in estimators_fs:\n",
    "    grid_search = GridSearchCV(estimator, param_grids_fs[name], scoring=['accuracy', 'precision', 'recall'], refit='precision', cv=3, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_models_fs[name] = [grid_search.best_estimator_, grid_search.best_score_]\n",
    "\n",
    "best_models_fs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91592cc3-4882-4c55-b44b-859eeaef7193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nogs': ['HadAngina',\n",
       "  'BMI',\n",
       "  'WeightInKilograms',\n",
       "  'HeightInMeters',\n",
       "  'SleepHours',\n",
       "  'PhysicalHealthDays',\n",
       "  'MentalHealthDays'],\n",
       " 'gs': ['HadAngina',\n",
       "  'BMI',\n",
       "  'WeightInKilograms',\n",
       "  'HeightInMeters',\n",
       "  'SleepHours',\n",
       "  'PhysicalHealthDays',\n",
       "  'MentalHealthDays'],\n",
       " 'fs': ['HadAngina',\n",
       "  'BMI',\n",
       "  'WeightInKilograms',\n",
       "  'HeightInMeters',\n",
       "  'SleepHours',\n",
       "  'PhysicalHealthDays',\n",
       "  'MentalHealthDays']}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_feature_names = {\n",
    "    'nogs': X_train.columns.tolist(),\n",
    "    'gs': X_train.columns.tolist(),\n",
    "    'fs': X_train[columns_to_keep].columns.tolist()\n",
    "}\n",
    "trained_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2db137e6-5a6d-4937-bacb-4a74aac98709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results with Selected Features and Grid Search Hyperparameters:\n",
      "                     accuracy  precision    recall  f1_score\n",
      "random_forest        0.867810   0.809289  0.508963  0.624916\n",
      "svm                  0.866401   0.805207  0.504578  0.620392\n",
      "logistic_regression  0.866401   0.805207  0.504578  0.620392\n",
      "Decision_tree        0.869386   0.808534  0.519280  0.632401\n",
      "SGD                  0.866401   0.805207  0.504578  0.620392\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to evaluate a single model\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_test, y_pred),\n",
    "        'precision': precision_score(y_test, y_pred),\n",
    "        'recall': recall_score(y_test, y_pred),\n",
    "        'f1_score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# Function to evaluate all models in a dictionary\n",
    "def evaluate_all_models(best_models, X_test, y_test):\n",
    "    results = {}\n",
    "    for name, model_info in best_models.items():\n",
    "        model = model_info[0]  # The best estimator\n",
    "        results[name] = evaluate_model(model, X_test, y_test)\n",
    "    return pd.DataFrame(results).T\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets (same as the original fs models)\n",
    "X_test_fs = filtered_df.drop(columns=\"HadHeartAttack\")\n",
    "y_test_fs = filtered_df[\"HadHeartAttack\"]\n",
    "\n",
    "# Evaluate the fs models\n",
    "fs_results = evaluate_all_models(best_models_fs, X_test_fs, y_test_fs)\n",
    "\n",
    "# Display the results\n",
    "print(\"Results with Selected Features and Grid Search Hyperparameters:\")\n",
    "print(fs_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e44ee990-1692-4a1a-a8a4-00766cea8a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for random_forest:\n",
      "[[54309  1860]\n",
      " [ 7615  7893]]\n",
      "\n",
      "Confusion Matrix for svm:\n",
      "[[54276  1893]\n",
      " [ 7683  7825]]\n",
      "\n",
      "Confusion Matrix for logistic_regression:\n",
      "[[54276  1893]\n",
      " [ 7683  7825]]\n",
      "\n",
      "Confusion Matrix for Decision_tree:\n",
      "[[54262  1907]\n",
      " [ 7455  8053]]\n",
      "\n",
      "Confusion Matrix for SGD:\n",
      "[[54276  1893]\n",
      " [ 7683  7825]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Columns to keep\n",
    "columns_to_keep = ['HadAngina', 'BMI', 'WeightInKilograms', 'HeightInMeters', 'SleepHours', 'PhysicalHealthDays', 'MentalHealthDays']\n",
    "\n",
    "# Filter the dataset to include only the selected columns plus the target column\n",
    "filtered_df = df[columns_to_keep + ['HadHeartAttack']]\n",
    "\n",
    "# Split the data into training and testing sets (same as the original fs models)\n",
    "X_test_fs = filtered_df.drop(columns=\"HadHeartAttack\")\n",
    "y_test_fs = filtered_df[\"HadHeartAttack\"]\n",
    "\n",
    "# Print confusion matrices for each fs model\n",
    "for name, model_info in best_models_fs.items():\n",
    "    model = model_info[0]  # The best estimator\n",
    "    predictions = model.predict(X_test_fs)\n",
    "    cm = confusion_matrix(y_test_fs, predictions)\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cb103c-3f97-4f8e-ad13-d25e47cf983f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
